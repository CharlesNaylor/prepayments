---
title: "2017031 - Prepayments by vintage, coupon, issuer"
output: html_notebook
---



```{r}
knitr::opts_chunk$set(include = FALSE)
library(knitr)
opts_knit$set(root.dir = "~/src/LondonMirror/Prepayments/")
setwd("~/src/LondonMirror/Prepayments/")
library(tidyverse)
library(lubridate)
library(rstan)
library(ggthemes)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

cpr <- read_csv("/data/prepayments/gnm_ii_pool_recent_cprs.csv") %>%
      rename(Date=X1)# %>% gather(cusip,value,-Date)
mar_data <- read_csv("/data/prepayments/201703 gnm_ii_data.csv") %>%
            rename(cusip=index) %>% select(-X1)
cpr <- cpr[,!is.na(cpr[6,])[1,]]
mar_data$cpr_3m <- NA
for(i in seq.int(nrow(mar_data))) {
  mar_data$cpr_3m[i] <- mean(as.matrix(cpr[4:6,mar_data$cusip[i]]))
}
```
Check distributions
```{r}
mar_data %>% select(-cusip) %>% gather(p_col,value) %>%
  ggplot(aes(x=value)) + facet_wrap(~p_col, scales = "free_x") + geom_histogram(bins=50)
```

UPB is multi-modal lognormal. Wonder if there isn't a confounding factor.

Average CPR by Vintage, Coupon, and issuer as in Barclay's Prepayment Outlook reports.
```{r}
mar_summary <- mar_data %>% na.omit %>% 
      mutate(coupon = security_interest_rate / 1000, vintage=year(origination_dt)) %>%
      group_by(coupon, vintage) %>%
      filter(vintage > 2003) %>%
      filter(coupon %in% c(3,3.5,4,4.5,5,5.5)) %>%
      summarize(WAC=round(mean(wac/1000),2), 
                `Balance ($B)`=round(sum(upb)/1e9, digits=1), 
                CPR=round(mean(value)*100,1)) %>%
      rename(Coupon=coupon, Vintage=vintage)
print(mar_summary)
```

Scaling

```{r}
mar_data <- mar_data %>% mutate(burnout = burnout * 5e-6, 
                                      cato = cato * 1, 
                                      incentive = incentive * 5e-4, 
                                      lockin = lockin * 200, 
                                      sato = sato * 1, 
                                      hpa = hpa * 5,
                                      upfront_mip = upfront_mip * 0.01)
```

Let's have a look

Median betas for point estimate:
```{r}
vb_betas <- p_vb$data %>% select(mid,beta,vintage) %>% spread(beta,mid)
global_betas <- extract(fit_phv, pars=c("beta"))[["beta"]]
colnames(global_betas) <- beta_labels
global_betas <- apply(global_betas,2,median)
intercept <- median(extract(fit_phv, pars=c("intercept"))[["intercept"]])
theta <- median(extract(fit_phv, pars=c("theta"))[["theta"]])
month_intercept <- apply(extract(fit_phv, 
                                 pars=c("month_intercept"))[["month_intercept"]],
                         2,median)
model_params = list(global_betas=global_betas, vb_betas=vb_betas, intercept=intercept,
                    month_intercept=month_intercept)
```

Estimate function (this is before multiplying by odds it's zero):
```{r}
cpr_hat <- function(x, model_params) {
  season = month(x$dt)
  p_betas = with(model_params,
                 global_betas + vb_betas[vb_betas$vintage == x$vintage,-1])
  p_alpha = with(model_params, intercept + month_intercept[season])
  ans <- sum(x[names(p_betas)] * p_betas)
  return(exp(ans + p_alpha))
}
```


```{r}
library(lubridate)
mar_data$cpr_hat <- NA
mar_data <- mar_data %>% mutate(vintage=year(origination_dt))
for(i in seq.int(nrow(mar_data))) {
  mar_data$cpr_hat[i] <- cpr_hat(x=mar_data[i,], model_params=model_params)
}
```


```{r}
mar_data %>% ggplot(aes(x=(1-theta)*cpr_hat)) + geom_histogram(bins=50)
```
Get current prepayment levels from last 6 months' CPR data
```{r}
jim <- round(100*as.matrix(cpr[,-1])) == 0
new_theta <- sum(na.omit(as.numeric(jim))) / length(na.omit(as.numeric(jim)))
```


```{r}
mar_summary <- mar_data %>%
  mutate(coupon=security_interest_rate / 1000) %>% group_by(coupon, vintage) %>%
      filter(vintage > 2003) %>% filter(coupon %in% c(3,3.5,4,4.5,5,5.5)) %>%
      summarize(WAC=round(mean(wac),2), 
                `Balance ($B)`=round(sum(upb)/1e9, digits=1), 
                `3M CPR`=round(mean(na.omit(cpr_3m))*100,1),
                `April CPR`=round(mean(cpr_hat),1),
                `April CPR w/0s`=round(mean((1-new_theta)*cpr_hat),1)) %>%
      rename(Coupon=coupon, Vintage=vintage)
print(mar_summary)
```

```{r}
mar_summary %>% select(Coupon, Vintage, `3M CPR`, `April CPR`, 
                       `April CPR w/0s`) %>% gather(CPR_type,CPR, -Coupon, -Vintage) %>%
  ggplot(aes(x=CPR, col=CPR_type, y=Vintage)) + facet_wrap(~Coupon) + 
    geom_point(shape="|", size=2)
```

Put the 0s in at the level observed over the last 6 months and it looks pretty good. Maybe I should through `prev_3m_cpr` in as a factor in a future version. Difficult on a pool-level, though. Does everyone else only fit on aggregate endos?

Anyway, something for Steve should include that table, I guess, and maybe a version of the graph above.
```{r}
mar_summary %>% write_excel_csv(path="/media/gdaa/Charles/prepayment/201703-Summary.csv")
```

Why am I missing some 3M CPRs? At this point I think I'd better just fill those in manually.

I'm going to make the table in Excel to save some time.

What's the standard deviation of pool-level mean forecasts by year and vintage?

```{r}
mar_data %>%  mutate(coupon=security_interest_rate / 1000) %>% 
  mutate(cpr_apr = (1-theta)*cpr_hat) %>%
  group_by(coupon, vintage) %>% 
  filter(vintage > 2003) %>%  filter(coupon %in% c(3,3.5,4,4.5,5,5.5)) %>%
  summarize(min=quantile(cpr_apr, 0.05),
            low=quantile(cpr_apr, 0.25),
            mid=quantile(cpr_apr, 0.5),
            high=quantile(cpr_apr, 0.75),
            max=quantile(cpr_apr, 0.95)) %>%
  ggplot(aes(y=vintage)) + facet_wrap(~coupon) + 
  geom_segment(aes(yend=vintage,x=min,xend=max)) + 
  geom_segment(aes(yend=vintage,x=low,xend=high,colour="red", alpha=0.65, size=2)) +
  geom_point(aes(x=mid)) + theme_minimal() + xlab("CPR") + ylab("Vintage") +
  ggtitle("Forecast CPR Distribution by Vintage and Coupon") + theme(legend.position="none")
```

Pretty tight, to be honest.

Let's look at effect trends

```{r}
output_xb <- function(x, model_params=model_params) {
  season = month(x$dt)
  p_betas = with(model_params,
                 global_betas + vb_betas[vb_betas$vintage == x$vintage,-1])
  return(data.frame(cusip=x$cusip, vintage=x$vintage, 
                    coupon=x$security_interest_rate / 1000, p_betas))
}
xb <- list()
for(i in seq.int(nrow(mar_data))) {
  xb[[i]] <- output_xb(mar_data[i,],model_params)
}
xb <- do.call("rbind",xb)

```

I really have to learn dplyr %>% rowwise() %>% do.

```{r}
xb %>% select(-cusip, -coupon) %>% gather(beta,value,-vintage) %>% 
  group_by(vintage, beta) %>% summarize(min=quantile(value,0.05),
                                  low=quantile(value,0.25),
                                  mid=quantile(value,0.5),
                                  high=quantile(value,0.75),
                                  max=quantile(value,0.95)) %>%
  ggplot(aes(x=vintage)) + facet_wrap(~beta) + ggtitle("XB Trends for March 2017", subtitle="(median effects of factors by vintage for March 2017)") +
    geom_ribbon(aes(ymin=min,ymax=max)) + 
    geom_ribbon(aes(ymin=low,ymax=high)) + 
      geom_line(aes(y=mid))
      
```

