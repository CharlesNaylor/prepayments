---
title: "20170223 Beta Regression directly in Stan"
output: html_notebook
---

With what I learned in the rstanarm regression yesterday, try rolling my own full beta regression in stan.

```{r, message=FALSE, warning=FALSE}
library(knitr)
opts_knit$set(root.dir = "~/src/LondonMirror/Prepayments/")
setwd("~/src/LondonMirror/Prepayments/")
library(tidyverse)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

sample_data = read_csv("data/samples2.csv") %>% 
                rename(pool_number=X1, as_of_date=X2)
#Scale it
sample_data <- sample_data %>% mutate(burnout = burnout * 1e-7, 
                                      cato = cato * 0.1, 
                                      next_month_cpr = next_month_cpr * 1e-2,
                                      incentive = incentive * 5e-5, 
                                      lockin = lockin * 200, 
                                      sato = sato * 1e-4, 
                                      upfront_mip = upfront_mip * 0.01)
#filter out negative CPRs
sample_data <- sample_data %>% filter(next_month_cpr >= 0)
```

Transform cpr from [0,1] to (0,1)

```{r}
N <- nrow(sample_data)
sample_data <- sample_data %>% 
  mutate(next_month_cpr2 = (next_month_cpr*(N-1) + 0.5)/N)
```

What is the relationship between `burnout` and `incentive`?

```{r}
sample_data %>% ggplot(aes(y=burnout, x=incentive)) + geom_point(alpha=0.1)
```

...significant. I may take out burnout for now. First let's do a clean run of my beta regression.

```{r}
N = nrow(sample_data)
N = 5000
stan_code = "/home/charles/src/LondonMirror/Prepayments/prepayments/stan/pool_beta.stan"
with(sample_data,
fit <<- stan(file=stan_code, model_name="beta pool",
            data=list(N=N, cpr=next_month_cpr2[1:N], cato=cato[1:N],
                      sato=sato[1:N], hpa=hpa[1:N], lockin=lockin[1:N],
                      burnout=burnout[1:N], incentive=incentive[1:N],
                    mip=upfront_mip[1:N], month=seasonality[1:N]),
          iter=1000, chains=4, sample_file="pool_beta.smpl",
          pars=c("phi"), include=F))
```

```{r}
print(fit, pars=c("log_lik","cpr_pred"), include=F)
```

It still looks to me like all these betas are the opposite of what they should be. Also seems weird that HPA is so insignificant.

For reference:
~~~~
phi = inv_logit(intercept + season[month] +
                     beta[1] * cato +
                     beta[2] * sato +
                     beta[3] * hpa +
                     beta[4] * lockin +
                     beta[5] * burnout +
                     beta[6] * incentive +
                     beta[7] * mip);
~~~~

The direct relationship between coefficients and `y` is inverse_logit: $$logit^{-1}(x) = \frac{1}{1+e^{-x}}$$ 

This means *all* coefficients are positive, I believe. I should probably set wider priors on the betas, as inv_logit(-2) = 0.12, and inv_logit(2) = 0.88, and I have prior $\beta \sim N(0,1)$.
```{r}
params <- extract(fit, pars=c("season", "beta", "intercept", "lambda"))
median_coefs <- sapply(params, function(x) {
    if(length(dim(x))>1){apply(x,2,median)} else {median(x)}
  })

inv_logit <- function(x) {1/(1+exp(-x))}

relevant <- c('cato', 'sato', 'hpa', 'lockin', 'burnout', 'incentive', 'upfront_mip')
pred_cpr <- function(x,b, details=F, dx=0) {
  dxx <- function(b,dx) {b+dx}
  ans <- c(b$intercept, b$season[x$seasonality], b$beta[1] * dxx(x$cato,dx), 
           b$beta[2] * dxx(x$sato,dx), b$beta[3] * dxx(x$hpa,dx), 
           b$beta[4] * dxx(x$lockin,dx), b$beta[5] * dxx(x$burnout,dx),
           b$beta[6] * dxx(x$incentive,dx), b$beta[7] * dxx(x$upfront_mip,dx))
  if(!details) {
    ans <- inv_logit(sum(ans))
  }
  return(ans)
}

jim <- cbind(t(sample_data[5001,relevant]),
             (pred_cpr(sample_data[5001,],median_coefs,T)[3:9]),
             (pred_cpr(sample_data[5001,],median_coefs,T,1)[3:9]),
             (pred_cpr(sample_data[5001,],median_coefs,T,-1)[3:9])
             )
jim
```

I think I'll reparameterize seasonal to combine the intercept; they're interacting now and it's confusing. Removing `burnout` is worth looking at, too.

```{r}
N = nrow(sample_data)
stan_code = "/home/charles/src/LondonMirror/Prepayments/prepayments/stan/pool_beta.stan"
with(sample_data,
fit <<- stan(file=stan_code, model_name="beta pool",
            data=list(N=N, cpr=next_month_cpr2[1:N], cato=cato[1:N],
                      sato=sato[1:N], hpa=hpa[1:N], lockin=lockin[1:N],
                      burnout=burnout[1:N], incentive=incentive[1:N],
                    mip=upfront_mip[1:N], month=seasonality[1:N]),
          iter=5000, chains=4, sample_file="pool_beta.smpl",
          pars=c("phi", "season", "intercept"), include=F))
```

```{r}
print(fit, pars=c("log_lik","cpr_pred"), include=F)
```

```{r}
params2 <- extract(fit, pars=c("shrunk_season", "beta"))
median_coefs2 <- sapply(params2, function(x) {
    if(length(dim(x))>1){apply(x,2,median)} else {median(x)}
  })

pred_cpr2 <- function(x,b, details=F, dx=0) {
  dxx <- function(b,dx) {b+dx}
  ans <- c(b$shrunk_season[x$seasonality], b$beta[1] * dxx(x$cato,dx), 
           b$beta[2] * dxx(x$sato,dx), b$beta[3] * dxx(x$hpa,dx), 
           b$beta[4] * dxx(x$lockin,dx), b$beta[5] * dxx(x$burnout,dx),
           b$beta[6] * dxx(x$incentive,dx), b$beta[7] * dxx(x$upfront_mip,dx))
  if(!details) {
    ans <- inv_logit(sum(ans))
  }
  return(ans)
}

jim <- cbind(t(sample_data[5001,relevant]),
             (pred_cpr(sample_data[5001,],median_coefs,T)[3:9]),
             (pred_cpr2(sample_data[5001,],median_coefs2,T)[2:8])
             )
jim
```

Check 5% confidence interval on posterior.
```{r}
cpr_pred <- extract(fit, pars=c("cpr_pred"))[[1]]
cpr_pred <- zapsmall(apply(cpr_pred,2,quantile,c(0.025,0.975)), digits=4)
sum(sample_data$next_month_cpr >= cpr_pred[1,] & sample_data$next_month_cpr <= cpr_pred[2,]) / 7991
```

Pretty good. If anything it's a bit wide. Which side is it on?

```{r}
sum(sample_data$next_month_cpr >= cpr_pred[1,]) / 7991
sum(sample_data$next_month_cpr <= cpr_pred[2,]) / 7991
```

Guess the 0 cutoff messes up 95% interval a bit. The first number is ideally 0.975.

What's the $R^2$ vs. median? Can't use straight-up $R^2$ for a logit model, so I'll just show SSR / N
```{r}
load("pool_beta2_fit.rData")
cpr_pred <- apply(extract(fit,pars=c("cpr_pred"))[[1]],2,median)
rm(fit)
sum((sample_data$next_month_cpr - cpr_pred)**2) / nrow(sample_data)
```
Meaning average off by 0.2. Not great.

How does it do against the first sample set?
```{r}
sample_data2 = read_csv("../data/samples.csv") %>%  select(-X1) %>%
        rename(pool_number=level_0, as_of_date=level_1)
#Scale it
sample_data2 <- sample_data2 %>% mutate(burnout = burnout * 1e-7, 
                                      cato = cato * 0.1, 
                                      next_month_cpr = next_month_cpr * 1e-2,
                                      incentive = incentive * 5e-5, 
                                      lockin = lockin * 200, 
                                      sato = sato * 1e-4, 
                                      upfront_mip = upfront_mip * 0.01)
#filter out negative CPRs
sample_data2 <- sample_data2 %>% filter(next_month_cpr >= 0)

cpr_pred2 <- c()
for(i in 1:nrow(sample_data2)) {
  cpr_pred2 <- pred_cpr2(sample_data2[i,], b=median_coefs2)
}

sum((sample_data2$next_month_cpr - cpr_pred2)**2) / nrow(sample_data2)
```

Robust, at least. Let's try one without burnout, see if the coefficient signs are more to my liking. Will start a new notebook.